{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- Preparing Grayscale Data for Pretrained Models (e.g., VGG16, InceptionV3)\n",
        "\n",
        "Most pretrained models (like VGG16, ResNet, or Inception) were trained on ImageNet, which contains RGB images of size 224√ó224.\n",
        "So, if we‚Äôre working with grayscale datasets (like MNIST having 32x32), we need to:\n",
        "1.Convert grayscale images ‚Üí 3-channel RGB.\n",
        "2.Resize 28√ó28 ‚Üí 224√ó224 pixels.\n",
        "\n",
        "'''\n",
        "# -------------------------------------------\n",
        "# Converting Grayscale Images to RGB & Resizing\n",
        "# -------------------------------------------\n",
        "\n",
        "# Step 1: Convert grayscale (28x28) ‚Üí RGB (28x28x3)\n",
        "# Repeat the single grayscale channel three times to simulate RGB.\n",
        "X_train_rgb = np.repeat(X_train[..., np.newaxis], 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test[..., np.newaxis], 3, axis=-1)\n",
        "\n",
        "# Step 2: Resize images to 224x224 (required by VGG16 / InceptionV3)\n",
        "X_train_incep = tf.image.resize(X_train_rgb, (224, 224)).numpy()\n",
        "X_test_incep = tf.image.resize(X_test_rgb, (224, 224)).numpy()\n",
        "\n",
        "# Display the new shapes to confirm\n",
        "print(\"X_train_rgb shape:\", X_train_rgb.shape)\n",
        "print(\"X_test_rgb shape:\", X_test_rgb.shape)\n",
        "print(\"X_train resized shape:\", X_train_incep.shape)\n",
        "print(\"X_test resized shape:\", X_test_incep.shape)\n",
        "\n",
        "'''\n",
        "‚ö†Ô∏è Note: Since CIFAR-10 images are already RGB (32√ó32√ó3), we only need to resize them to (224√ó224√ó3) for pretrained models like VGG16 or InceptionV3.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "yqLN8W8dPiO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3gkj2f5UnQF"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# üß† CIFAR-10 Classification using Pretrained VGG16 (Transfer Learning)\n",
        "# ================================================================\n",
        "'''\n",
        "- CIFAR-10 has 60,000 small (32√ó32) images in 10 categories.\n",
        "- VGG16 requires 224√ó224 images, so we resize them.\n",
        "- preprocess_input() scales the data like ImageNet (the dataset VGG16 was trained on).\n",
        "- The base layers of VGG16 are frozen so we don‚Äôt retrain them, only train the new Dense layers added on top.\n",
        "- Transfer learning lets us use pretrained knowledge on large datasets (like ImageNet) for smaller ones (like CIFAR-10).\n",
        "'''\n",
        "# -----------------------------\n",
        "# Import Required Libraries\n",
        "# -----------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Load and Explore CIFAR-10\n",
        "# -----------------------------\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(\"Original CIFAR-10 shapes:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "# Show some random samples\n",
        "plt.figure(figsize=(6,3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.title(f\"Label: {y_train[i][0]}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Sample CIFAR-10 Images\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Preprocess and Resize\n",
        "# -----------------------------\n",
        "# Resize from (32x32) to (224x224) for VGG16 input\n",
        "X_train_resized = tf.image.resize(X_train, (224, 224))\n",
        "X_test_resized = tf.image.resize(X_test, (224, 224))\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)\n",
        "\n",
        "# Apply VGG16 preprocessing (scales pixels to match ImageNet expectations)\n",
        "X_train_pre = preprocess_input(X_train_resized)\n",
        "X_test_pre = preprocess_input(X_test_resized)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# -----------------------------\n",
        "# Load Pretrained VGG16 Base\n",
        "# -----------------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# Freeze convolutional base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# -----------------------------\n",
        "# Build Transfer Learning Model\n",
        "# -----------------------------\n",
        "vgg_model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "vgg_model.summary()\n",
        "\n",
        "# -----------------------------\n",
        "# Train the Model\n",
        "# -----------------------------\n",
        "history = vgg_model.fit(X_train_pre, y_train_cat,\n",
        "                        epochs=5,\n",
        "                        batch_size=64,\n",
        "                        validation_split=0.2)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate the Model\n",
        "# -----------------------------\n",
        "test_loss, test_acc = vgg_model.evaluate(X_test_pre, y_test_cat)\n",
        "print(f\"\\n‚úÖ VGG16 (Transfer Learning) Test Accuracy: {test_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üåê CIFAR-10 Classification using Pretrained InceptionV3 (Transfer Learning)\n",
        "# ================================================================\n",
        "\n",
        "# -----------------------------\n",
        "# Import Required Libraries\n",
        "# -----------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Load and Explore CIFAR-10\n",
        "# -----------------------------\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(\"CIFAR-10 shapes:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "# Show a few sample images\n",
        "plt.figure(figsize=(6,3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.title(f\"Label: {y_train[i][0]}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Sample CIFAR-10 Images\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Preprocess & Resize\n",
        "# -----------------------------\n",
        "# InceptionV3 expects 224x224 images\n",
        "X_train_resized = tf.image.resize(X_train, (224, 224))\n",
        "X_test_resized = tf.image.resize(X_test, (224, 224))\n",
        "\n",
        "# Convert to numpy\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "X_test_resized = np.array(X_test_resized)\n",
        "\n",
        "# Preprocess input as required by InceptionV3\n",
        "X_train_pre = preprocess_input(X_train_resized)\n",
        "X_test_pre = preprocess_input(X_test_resized)\n",
        "\n",
        "# -----------------------------\n",
        "# Build Pretrained Model\n",
        "# -----------------------------\n",
        "# Load base InceptionV3 model\n",
        "base_model_incep = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# -----------------------------\n",
        "# Explanation for New Learners\n",
        "# -----------------------------\n",
        "# - include_top=False removes the final classifier head (used for ImageNet)\n",
        "# - We'll add our own Dense layers suited for 10 CIFAR classes\n",
        "# - \"Freezing\" layers means their weights won't change during training\n",
        "# - Later, we can unfreeze some for fine-tuning if needed\n",
        "\n",
        "# Freeze base layers\n",
        "for layer in base_model_incep.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# -----------------------------\n",
        "# Add Custom Classification Head\n",
        "# -----------------------------\n",
        "inception_model = Sequential([\n",
        "    base_model_incep,\n",
        "    GlobalAveragePooling2D(), # for flattened . we use max for 2d. gobal can be used for both flattened as well as 2d\n",
        "    # Replaces Flatten for better feature aggregation\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "inception_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "inception_model.summary()\n",
        "\n",
        "# -----------------------------\n",
        "# Train the Model\n",
        "# -----------------------------\n",
        "history_incep = inception_model.fit(X_train_pre, y_train,\n",
        "                                    validation_split=0.2,\n",
        "                                    epochs=5,\n",
        "                                    batch_size=64)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate the Model\n",
        "# -----------------------------\n",
        "test_loss, test_acc = inception_model.evaluate(X_test_pre, y_test)\n",
        "print(f\"\\n‚úÖ InceptionV3 (Transfer Learning) Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "\n",
        "'''\n",
        "# fine tuning : include_top\n",
        "# top of any model dependent on dataset . so we remove the head because we dont need there head . we would be using our own head\n",
        "# pre training vs fine tuning\n",
        "# pretraining : using a architecture but training on our own . discarding its previous weights and learning\n",
        "# fine tune :keep train weights as it is . remove their top/head . add our head . freeze the previous weights of original architectire. this way only weights of our own layers gets trained\n",
        "# unfreeze some layers in fine tune if the previous original model learning a bit cotrdictory with outr dataset . it would upadte weights of both : our new head and unfreezed layers . better convergence\n",
        "\n",
        "# transfer learning : Pretrain + finetune\n",
        "'''\n"
      ],
      "metadata": {
        "id": "anEr1W7kNpqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üåà Data Augmentation and Training with InceptionV3\n",
        "# ================================================================\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# -----------------------------\n",
        "# Why Data Augmentation?\n",
        "# -----------------------------\n",
        "# Neural networks often overfit when training data is limited or repetitive.\n",
        "# Data augmentation artificially increases dataset diversity by applying random\n",
        "# transformations (rotations, shifts, flips) to input images during training.\n",
        "\n",
        "# Define augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,        # Randomly rotate images by ¬±15 degrees\n",
        "    width_shift_range=0.1,    # Shift images horizontally by ¬±10%\n",
        "    height_shift_range=0.1,   # Shift images vertically by ¬±10%\n",
        "    horizontal_flip=True      # Randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Fit the generator to the training data\n",
        "# (required to compute internal statistics, though not needed for all transforms)\n",
        "datagen.fit(X_train_pre)\n",
        "\n",
        "# -----------------------------\n",
        "# Train the Model with Augmentation\n",
        "# -----------------------------\n",
        "# The generator dynamically produces augmented images during training.\n",
        "# This means the model never sees the exact same image twice ‚Äî improving robustness.\n",
        "\n",
        "history_incep = inception_model.fit(\n",
        "    datagen.flow(X_train_pre, y_train, batch_size=64),  # use generator instead of raw data\n",
        "    epochs=3,\n",
        "    validation_data=(X_test_pre, y_test),               # evaluate on unaugmented test data\n",
        "    verbose=1\n",
        ")\n",
        "'''\n",
        "- ImageDataGenerator: Real-time augmentation that slightly alters images each epoch to simulate new data.\n",
        "\n",
        "- fit() vs. flow():\n",
        "fit() prepares the generator (not always needed).\n",
        "flow() feeds batches of augmented data to the model.\n",
        "\n",
        "- Goal: This improves model generalization and reduces overfitting, especially when fine-tuning pretrained networks.\n",
        "'''"
      ],
      "metadata": {
        "id": "yaio3_6r4A17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}